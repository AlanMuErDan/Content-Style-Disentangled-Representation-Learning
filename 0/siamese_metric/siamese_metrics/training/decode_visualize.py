#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†æ½œåœ¨ç¼–ç è§£ç ä¸ºPNGå›¾åƒè¿›è¡Œå¯è§†åŒ–
ç”¨äºæ£€æŸ¥æ•°æ®å†…å®¹æ˜¯å¦ä¸ºå­—ä½“å›¾åƒ
"""
import os
import sys
import torch
import torch.nn as nn
import numpy as np
from PIL import Image
import yaml
from typing import Optional, Tuple
from torchvision import transforms

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append('/scratch/gz2199/Content-Style-Disentangled-Representation-Learning/Content-Style-Disentangled-Representation-Learning')
from models import build_decoder

# VAEè§£ç å™¨ç›¸å…³å‡½æ•°
def _load_config(path: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(path, "r") as f:
        cfg = yaml.safe_load(f)
    return cfg["vae"] if "vae" in cfg else cfg

def load_vae_decoder(
    config_path: str = "/scratch/gz2199/Content-Style-Disentangled-Representation-Learning/Content-Style-Disentangled-Representation-Learning/configs/config.yaml",
    ckpt_path: str = "/scratch/gz2199/Content-Style-Disentangled-Representation-Learning/0/1/0/vae_best_ckpt.pth",
    device: str = "cuda"
) -> Tuple[torch.nn.Module, dict, torch.device]:
    """
    åŠ è½½VAEè§£ç å™¨
    
    Returns:
        decoder  â€“ torch.nn.Module (eval mode)
        cfg      â€“ dict (é…ç½®)
        device   â€“ torch.device
    """
    device = torch.device(device if torch.cuda.is_available() else "cpu")
    cfg = _load_config(config_path)

    decoder = build_decoder(
        name=cfg["decoder"],
        img_size=cfg["img_size"],
        latent_channels=cfg.get("latent_channels", 4),
    ).to(device).eval()

    # åŠ è½½æƒé‡
    ckpt = torch.load(ckpt_path, map_location=device)
    if "decoder" in ckpt:
        decoder.load_state_dict(ckpt["decoder"])
    else:
        # å¦‚æœcheckpointç›´æ¥æ˜¯decoderçŠ¶æ€
        decoder.load_state_dict(ckpt)

    print(f"[INFO] Loaded VAE decoder on {device}")
    return decoder, cfg, device

def load_latents_from_local(local_path: str, map_location: str = "cpu"):
    """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½æ½œåœ¨ç¼–ç  - å¤šç§å°è¯•æ–¹å¼"""
    if not os.path.exists(local_path):
        raise FileNotFoundError(f"Local file not found: {local_path}")
    
    print(f"[INFO] Loading from local file: {local_path}")
    
    # æ£€æŸ¥æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
    file_size = os.path.getsize(local_path)
    print(f"[INFO] File size: {file_size / (1024*1024):.2f} MB")
    
    # å°è¯•å¤šç§åŠ è½½æ–¹å¼
    methods = [
        ("Standard torch.load", lambda: torch.load(local_path, map_location=map_location)),
        ("Weights only", lambda: torch.load(local_path, map_location=map_location, weights_only=True)),
        ("With pickle protocol", lambda: torch.load(local_path, map_location=map_location, pickle_protocol=2)),
    ]
    
    for method_name, load_func in methods:
        try:
            print(f"[INFO] Trying {method_name}...")
            obj = load_func()
            print(f"[INFO] Successfully loaded with {method_name}")
            return obj
        except Exception as e:
            print(f"[WARN] {method_name} failed: {e}")
            continue
    
    # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•è¯»å–åŸå§‹æ•°æ®
    try:
        print(f"[INFO] Trying to read raw data...")
        with open(local_path, 'rb') as f:
            data = f.read(1000)  # è¯»å–å‰1000å­—èŠ‚
            print(f"[INFO] File header (hex): {data[:50].hex()}")
            print(f"[INFO] File header (ascii): {data[:50]}")
    except Exception as e:
        print(f"[WARN] Cannot read raw data: {e}")
    
    raise RuntimeError(f"All loading methods failed for {local_path}")

@torch.no_grad()
def decode_to_image(decoder: nn.Module, z: torch.Tensor, cfg: dict, device: torch.device) -> torch.Tensor:
    """
    ä½¿ç”¨VAEè§£ç å™¨å°†æ½œåœ¨ç¼–ç è§£ç ä¸ºå›¾åƒ
    
    Args:
        decoder: VAEè§£ç å™¨
        z: æ½œåœ¨ç¼–ç  [C,H,W] æˆ–å…¶ä»–æ ¼å¼
        cfg: é…ç½®å­—å…¸
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        img: å›¾åƒå¼ é‡ [C,H,W] èŒƒå›´[0,1]
    """
    # æ£€æŸ¥å¹¶ä¿®å¤æ•°æ®ç±»å‹ä¸åŒ¹é…é—®é¢˜
    print(f"    åŸå§‹æ½œåœ¨ç¼–ç ç±»å‹: {z.dtype}")
    
    # è·å–è§£ç å™¨çš„å‚æ•°ç±»å‹
    decoder_dtype = next(decoder.parameters()).dtype
    print(f"    è§£ç å™¨å‚æ•°ç±»å‹: {decoder_dtype}")
    
    # è½¬æ¢æ½œåœ¨ç¼–ç ä¸ºè§£ç å™¨ç›¸åŒçš„ç±»å‹
    if z.dtype != decoder_dtype:
        print(f"    è½¬æ¢æ½œåœ¨ç¼–ç ç±»å‹: {z.dtype} -> {decoder_dtype}")
        z = z.to(dtype=decoder_dtype)
    
    # ç¡®ä¿æ½œåœ¨ç¼–ç æ ¼å¼æ­£ç¡®
    if z.dim() == 2:
        # å¦‚æœæ˜¯2Dï¼Œå°è¯•é‡å¡‘ä¸º3D
        if z.shape == (16, 4):
            z = z.view(4, 4, 4)  # [C, H, W]
        else:
            raise ValueError(f"Unexpected 2D tensor shape: {z.shape}")
    elif z.dim() == 1:
        # å¦‚æœæ˜¯1Dï¼Œé‡å¡‘ä¸º3D
        if z.numel() == 64:  # 4*4*4
            z = z.view(4, 4, 4)
        else:
            raise ValueError(f"Unexpected 1D tensor size: {z.numel()}")
    elif z.dim() == 3:
        # 3Då¼ é‡ [H, W, C] -> [C, H, W]ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°æ’åˆ—
        if z.shape == (16, 16, 4):
            z = z.permute(2, 0, 1)  # [H, W, C] -> [C, H, W]
            print(f"    é‡æ–°æ’åˆ—ç»´åº¦: (16,16,4) -> {z.shape}")
    elif z.dim() != 3:
        raise ValueError(f"Latent must be 1D, 2D, or 3D, got {z.dim()}D")
    
    # æ·»åŠ batchç»´åº¦å¹¶ç§»åˆ°è®¾å¤‡
    z_batch = z.unsqueeze(0).to(device=device, dtype=decoder_dtype)  # [1, C, H, W]
    
    # è§£ç 
    with torch.no_grad():
        recon = decoder(z_batch).squeeze(0).cpu()  # [C, H, W]
    
    # ç¡®ä¿è¾“å‡ºåœ¨[0,1]èŒƒå›´
    recon = torch.clamp(recon, 0, 1)
    
    return recon

def save_tensor_as_png(tensor: torch.Tensor, save_path: str):
    """å°†tensorä¿å­˜ä¸ºPNGå›¾åƒ"""
    # ç¡®ä¿tensoræ˜¯[C, H, W]æ ¼å¼
    if tensor.ndim == 3:
        # å¦‚æœæ˜¯å¤šé€šé“ï¼Œå–ç¬¬ä¸€ä¸ªé€šé“æˆ–è½¬ä¸ºç°åº¦
        if tensor.shape[0] > 1:
            tensor = tensor.mean(dim=0, keepdim=True)  # è½¬ä¸ºç°åº¦
        tensor = tensor[0]  # å»é™¤é€šé“ç»´åº¦
    
    # è½¬æ¢ä¸ºnumpyå¹¶è°ƒæ•´åˆ°[0, 255]
    img_array = (tensor.numpy() * 255).astype(np.uint8)
    
    # åˆ›å»ºPILå›¾åƒå¹¶ä¿å­˜
    img = Image.fromarray(img_array, mode='L')  # ç°åº¦å›¾åƒ
    img.save(save_path)
    print(f"[INFO] å›¾åƒå·²ä¿å­˜åˆ°: {save_path}")

class LatentAccessor:
    def __init__(self, raw, layout: str = "style_content"):
        if isinstance(raw, dict):
            if "latents" in raw:
                raw = raw["latents"]
            elif "data" in raw:
                raw = raw["data"]
        self.raw = raw
        self.layout = layout
        
        if isinstance(raw, torch.Tensor):
            self.total_samples = raw.shape[0]
            print(f"[INFO] æ€»æ ·æœ¬æ•°: {self.total_samples}")
            print(f"[INFO] æ•°æ®å½¢çŠ¶: {raw.shape}")
            
            # å‡è®¾æ•°æ®ç»„ç»‡ç»“æ„
            self.num_characters = 500
            self.num_styles_per_char = self.total_samples // self.num_characters
            print(f"[INFO] æ¨æ–­ç»“æ„: {self.num_characters} å­—ç¬¦ Ã— {self.num_styles_per_char} é£æ ¼/å­—ç¬¦")

    def get(self, content_i: int, style_p: int) -> torch.Tensor:
        r = self.raw
        if isinstance(r, torch.Tensor):
            if content_i >= self.num_characters:
                raise IndexError(f"content_i {content_i} >= num_characters {self.num_characters}")
            if style_p >= self.num_styles_per_char:
                raise IndexError(f"style_p {style_p} >= num_styles_per_char {self.num_styles_per_char}")
                
            idx = content_i * self.num_styles_per_char + style_p
            if idx >= self.total_samples:
                raise IndexError(f"Computed index {idx} >= total_samples {self.total_samples}")
            
            return r[idx]
        else:
            raise RuntimeError("Unsupported format")

def visualize_latents_from_pt(
    pt_file_path: str = "/scratch/gz2199/Content-Style-Disentangled-Representation-Learning/Font-Latent-Full-PT/font_latents_v2.pt",
    save_dir: str = "/scratch/gz2199/Content-Style-Disentangled-Representation-Learning/0/1/0/",
    num_samples: int = 20,
    device: str = "cuda" if torch.cuda.is_available() else "cpu"
):
    """
    ä»PTæ–‡ä»¶ä¸­è§£ç æ½œåœ¨ç¼–ç å¹¶ä¿å­˜ä¸ºPNGå›¾åƒ
    
    Args:
        pt_file_path: PTæ–‡ä»¶è·¯å¾„
        save_dir: ä¿å­˜ç›®å½•
        num_samples: è¦ä¿å­˜çš„æ ·æœ¬æ•°é‡
        device: è®¡ç®—è®¾å¤‡
    """
    print("ğŸ¨ å¼€å§‹å¯è§†åŒ–æ½œåœ¨ç¼–ç ...")
    print(f"ğŸ“ PTæ–‡ä»¶: {pt_file_path}")
    print(f"ğŸ’¾ ä¿å­˜ç›®å½•: {save_dir}")
    print(f"ğŸ”¢ æ ·æœ¬æ•°é‡: {num_samples}")
    print(f"ğŸ–¥ï¸  è®¾å¤‡: {device}")
    
    # 1. åŠ è½½æ•°æ®
    print("\nğŸ“¥ åŠ è½½æ½œåœ¨ç¼–ç æ•°æ®...")
    try:
        raw_data = load_latents_from_local(pt_file_path, map_location="cpu")
        accessor = LatentAccessor(raw_data)
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return
    
    # 2. åŠ è½½VAEè§£ç å™¨
    print("\nğŸ”§ åŠ è½½VAEè§£ç å™¨...")
    try:
        decoder, cfg, device_used = load_vae_decoder(device=device)
    except Exception as e:
        print(f"âŒ åŠ è½½VAEè§£ç å™¨å¤±è´¥: {e}")
        return
    
    # 3. åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(save_dir, exist_ok=True)
    
    # 4. è§£ç å¹¶ä¿å­˜æ ·æœ¬
    print(f"\nğŸ–¼ï¸  å¼€å§‹è§£ç å’Œä¿å­˜ {num_samples} ä¸ªæ ·æœ¬...")
    
    successful_saves = 0
    
    for i in range(num_samples):
        try:
            # é€‰æ‹©ä¸åŒçš„å†…å®¹å’Œé£æ ¼ç»„åˆ
            content_idx = i % min(10, accessor.num_characters)  # å¾ªç¯ä½¿ç”¨å‰10ä¸ªå­—ç¬¦
            style_idx = (i // 10) % min(10, accessor.num_styles_per_char)  # å¾ªç¯ä½¿ç”¨å‰10ç§é£æ ¼
            
            print(f"  å¤„ç†æ ·æœ¬ {i+1}/{num_samples}: content={content_idx}, style={style_idx}")
            
            # è·å–æ½œåœ¨ç¼–ç 
            latent = accessor.get(content_idx, style_idx)
            print(f"    æ½œåœ¨ç¼–ç å½¢çŠ¶: {latent.shape}")
            
            # è§£ç ä¸ºå›¾åƒ
            img_tensor = decode_to_image(decoder, latent, cfg, device_used)
            print(f"    è§£ç å›¾åƒå½¢çŠ¶: {img_tensor.shape}")
            
            # ä¿å­˜å›¾åƒ
            save_path = os.path.join(save_dir, f"sample_{i+1:03d}_c{content_idx}_s{style_idx}.png")
            save_tensor_as_png(img_tensor, save_path)
            
            successful_saves += 1
            
        except Exception as e:
            print(f"    âŒ æ ·æœ¬ {i+1} å¤„ç†å¤±è´¥: {e}")
            continue
    
    print(f"\nâœ… å®Œæˆ! æˆåŠŸä¿å­˜äº† {successful_saves}/{num_samples} ä¸ªå›¾åƒ")
    print(f"ğŸ“ å›¾åƒä¿å­˜åœ¨: {save_dir}")
    
    # 5. æ˜¾ç¤ºæ•°æ®ä¿¡æ¯æ€»ç»“
    print(f"\nğŸ“Š æ•°æ®ä¿¡æ¯æ€»ç»“:")
    print(f"  - æ€»æ ·æœ¬æ•°: {accessor.total_samples}")
    print(f"  - æ¨æ–­å­—ç¬¦æ•°: {accessor.num_characters}")
    print(f"  - æ¯å­—ç¬¦é£æ ¼æ•°: {accessor.num_styles_per_char}")
    if hasattr(accessor.raw, 'shape'):
        print(f"  - åŸå§‹æ•°æ®å½¢çŠ¶: {accessor.raw.shape}")

def quick_check_samples():
    """å¿«é€Ÿæ£€æŸ¥å‡ ä¸ªæ ·æœ¬"""
    print("ğŸ” å¿«é€Ÿæ£€æŸ¥æ ·æœ¬...")
    visualize_latents_from_pt(num_samples=5)

def check_more_samples():
    """æ£€æŸ¥æ›´å¤šæ ·æœ¬"""
    print("ğŸ” æ£€æŸ¥æ›´å¤šæ ·æœ¬...")
    visualize_latents_from_pt(num_samples=50)

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "more":
        check_more_samples()
    else:
        print("ğŸ” å¯åŠ¨å¿«é€Ÿæ ·æœ¬æ£€æŸ¥...")
        print("ğŸ’¡ æç¤º: ä½¿ç”¨ 'python decode_visualize.py more' æ£€æŸ¥æ›´å¤šæ ·æœ¬")
        quick_check_samples()